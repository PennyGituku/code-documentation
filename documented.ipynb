{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch & TorchVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import LightningModule, LightningDataModule, Trainer\n",
    "import lightning.pytorch as L\n",
    "print(L.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow (unused in current logic, possibly for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD IMAGE PATHS & LABELS FROM DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0 = '/kaggle/input/mushroom1/merged_dataset'\n",
    "\n",
    "classes = []\n",
    "paths = []\n",
    "for dirname, _, filenames in os.walk(dir0):\n",
    "    for filename in filenames:\n",
    "        classes.append(dirname.split('/')[-1])\n",
    "        paths.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ImageFolder dataset to access class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0 = datasets.ImageFolder(root=dir0)\n",
    "class_names = dataset0.classes\n",
    "print(class_names)\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "N = list(range(len(classes)))\n",
    "normal_mapping = dict(zip(class_names, N))\n",
    "reverse_mapping = dict(zip(N, class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A DATAFRAME OF PATHS AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'path': paths, 'class': classes})\n",
    "data['label'] = data['class'].map(normal_mapping)\n",
    "print(f\"Total images: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE IMAGE TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVERT DATAFRAME TO LIST OF (PATH, LABEL) TUPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_label_list(df):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame with image paths and labels into a list of tuples.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'path' and 'label' columns.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: List of (image_path, label) tuples.\n",
    "    \"\"\"\n",
    "    return [(row['path'], row['label']) for _, row in df.iterrows()]\n",
    "\n",
    "path_label = create_path_label_list(data)\n",
    "path_label = random.sample(path_label, 20000)\n",
    "print(len(path_label))\n",
    "print(path_label[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE CUSTOM DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset to load images from file paths and return transformed images.\n",
    "\n",
    "    Args:\n",
    "        path_label (List[Tuple[str, int]]): List of (image_path, label) tuples.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, int]: Transformed image tensor and its label.\n",
    "    \"\"\"\n",
    "    def __init__(self, path_label, transform=None):\n",
    "        self.path_label = path_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.path_label[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE LIGHTNING DATA MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning DataModule for loading and batching image data.\n",
    "\n",
    "    Handles both custom datasets and torchvision ImageFolder datasets.\n",
    "\n",
    "    Args:\n",
    "        data_source (str): Either 'custom' or 'imagefolder'.\n",
    "        path_label (List[Tuple[str, int]]): Data for custom loader.\n",
    "        root_dir (str): Directory for ImageFolder loader.\n",
    "        batch_size (int): Batch size for training/validation.\n",
    "        train_split (float): Train/validation split ratio.\n",
    "        custom_transform (callable, optional): Custom image transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source=None, path_label=None, root_dir=None,\n",
    "                 batch_size=32, train_split=0.8, custom_transform=None):\n",
    "        super().__init__()\n",
    "        self.data_source = data_source or ('custom' if path_label else 'imagefolder')\n",
    "        self.path_label = path_label\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.transform = custom_transform or transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Prepares datasets for training and validation based on selected data source.\n",
    "        \"\"\"\n",
    "        if self.data_source == 'custom':\n",
    "            dataset = CustomDataset(self.path_label, self.transform)\n",
    "            train_size = int(self.train_split * len(dataset))\n",
    "            self.train_dataset = torch.utils.data.Subset(dataset, range(train_size))\n",
    "            self.val_dataset = torch.utils.data.Subset(dataset, range(train_size, len(dataset)))\n",
    "        elif self.data_source == 'imagefolder':\n",
    "            dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
    "            train_size = int(self.train_split * len(dataset))\n",
    "            val_size = len(dataset) - train_size\n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        if self.data_source == 'imagefolder':\n",
    "            return len(datasets.ImageFolder(root=self.root_dir).classes)\n",
    "        elif self.data_source == 'custom':\n",
    "            return len(set([label for _, label in self.path_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL USING TIMM AND LIGHTNINGMODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "class ConvolutionalNetwork(LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch LightningModule using a pretrained ResNet152 from TIMM for image classification.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of target classes for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = timm.create_model('resnet152', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        return self.base_model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Sets up Adam optimizer.\"\"\"\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    datamodule = DataModule(path_label=path_label)\n",
    "    datamodule.setup()\n",
    "\n",
    "    model = ConvolutionalNetwork(num_classes=len(class_names))\n",
    "    trainer = Trainer(max_epochs=4, accelerator=\"cpu\", devices=1)\n",
    "    trainer.fit(model, datamodule)\n",
    "\n",
    "    # TESTING\n",
    "    datamodule.setup(stage='test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISPLAY TEST IMAGE GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in datamodule.test_dataloader():\n",
    "    break\n",
    "\n",
    "im = make_grid(images, nrow=8)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "\n",
    "# Inverse transform for visualization\n",
    "inv_normalize = transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
    "                                     std=[1 / 0.229, 1 / 0.224, 1 / 0.225])\n",
    "im = inv_normalize(im)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL WITH CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cpu\")\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in datamodule.test_dataloader():\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
